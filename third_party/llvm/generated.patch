Auto generated patch. Do not edit or delete it, even if empty.
diff -ruN --strip-trailing-cr a/clang/tools/clang-format/clang-format-test.el b/clang/tools/clang-format/clang-format-test.el
--- a/clang/tools/clang-format/clang-format-test.el
+++ b/clang/tools/clang-format/clang-format-test.el
@@ -58,16 +58,16 @@
        (should-not delete)
        (should-not display)
        (should (equal args
-                      '("-output-replacements-xml" "-assume-filename" "foo.cpp"
-                        "-fallback-style" "none"
+                      '("--output-replacements-xml" "--assume-filename" "foo.cpp"
+                        "--fallback-style" "none"
                         ;; Beginning of buffer, no byte-order mark.
-                        "-offset" "0"
+                        "--offset" "0"
                         ;; We have two lines with 2×2 bytes for the umlauts,
                         ;; 1 byte for the line ending, and 3 bytes for the
                         ;; other ASCII characters each.
-                        "-length" "16"
+                        "--length" "16"
                         ;; Length of a single line (without line ending).
-                        "-cursor" "7")))))))
+                        "--cursor" "7")))))))
 
 (ert-deftest clang-format-buffer--process-encoding ()
   "Tests that text is sent to the clang-format process in the
diff -ruN --strip-trailing-cr a/lldb/test/Shell/Unwind/trap_frame_sym_ctx.test b/lldb/test/Shell/Unwind/trap_frame_sym_ctx.test
--- a/lldb/test/Shell/Unwind/trap_frame_sym_ctx.test
+++ b/lldb/test/Shell/Unwind/trap_frame_sym_ctx.test
@@ -15,7 +15,7 @@
 process launch
 # CHECK: stop reason = breakpoint 1.1
 
-thread backtrace -u
+thread backtrace
 # CHECK: frame #0: {{.*}}`bar
 # CHECK: frame #1: {{.*}}`tramp
 # CHECK: frame #2: {{.*}}`main
diff -ruN --strip-trailing-cr a/llvm/lib/Target/NVPTX/NVPTXProxyRegErasure.cpp b/llvm/lib/Target/NVPTX/NVPTXProxyRegErasure.cpp
--- a/llvm/lib/Target/NVPTX/NVPTXProxyRegErasure.cpp
+++ b/llvm/lib/Target/NVPTX/NVPTXProxyRegErasure.cpp
@@ -78,7 +78,11 @@
         assert(InOp.isReg() && "ProxyReg input should be a register.");
         assert(OutOp.isReg() && "ProxyReg output should be a register.");
         RemoveList.push_back(&MI);
-        RAUWBatch.try_emplace(OutOp.getReg(), InOp.getReg());
+        Register replacement = InOp.getReg();
+        // Check if the replacement itself has been replaced.
+        if (auto it = RAUWBatch.find(replacement); it != RAUWBatch.end())
+          replacement = it->second;
+        RAUWBatch.try_emplace(OutOp.getReg(), replacement);
         break;
       }
       }
diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp b/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp
--- a/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp
+++ b/llvm/lib/Transforms/Vectorize/LoadStoreVectorizer.cpp
@@ -998,32 +998,10 @@
   LLVM_DEBUG(dbgs() << "LSV: isSafeToMove(" << *ChainElem << " -> "
                     << *ChainBegin << ")\n");
 
-  assert(isa<LoadInst>(ChainElem) == IsLoadChain &&
-         isa<LoadInst>(ChainBegin) == IsLoadChain);
-
+  assert(isa<LoadInst>(ChainElem) == IsLoadChain);
   if (ChainElem == ChainBegin)
     return true;
 
-  if constexpr (IsLoadChain) {
-    // If ChainElem depends on ChainBegin, they're not safe to reorder.
-    SmallVector<Instruction *, 8> Worklist;
-    Worklist.emplace_back(ChainElem);
-    while (!Worklist.empty()) {
-      Instruction *I = Worklist.pop_back_val();
-      for (Use &O : I->operands()) {
-        if (isa<PHINode>(O))
-          continue;
-        if (auto *J = dyn_cast<Instruction>(O)) {
-          if (J == ChainBegin) {
-            LLVM_DEBUG(dbgs() << "LSV: dependent loads; not safe to reorder\n");
-            return false;
-          }
-          Worklist.emplace_back(J);
-        }
-      }
-    }
-  }
-
   // Invariant loads can always be reordered; by definition they are not
   // clobbered by stores.
   if (isInvariantLoad(ChainElem))
diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/proxy-reg-erasure.mir b/llvm/test/CodeGen/NVPTX/proxy-reg-erasure.mir
--- a/llvm/test/CodeGen/NVPTX/proxy-reg-erasure.mir
+++ b/llvm/test/CodeGen/NVPTX/proxy-reg-erasure.mir
@@ -0,0 +1,98 @@
+# RUN: llc %s --run-pass=nvptx-proxyreg-erasure -march=nvptx64 -o - | FileCheck %s
+
+--- |
+  ; ModuleID = 'third-party/llvm-project/llvm/test/CodeGen/NVPTX/proxy-reg-erasure-mir.ll'
+  source_filename = "third-party/llvm-project/llvm/test/CodeGen/NVPTX/proxy-reg-erasure-mir.ll"
+  target datalayout = "e-i64:64-i128:128-v16:16-v32:32-n16:32:64"
+
+  declare <4 x i32> @callee_vec_i32()
+
+  define <4 x i32> @check_vec_i32() {
+    %ret = call <4 x i32> @callee_vec_i32()
+    ret <4 x i32> %ret
+  }
+
+...
+---
+name:            check_vec_i32
+alignment:       1
+exposesReturnsTwice: false
+legalized:       false
+regBankSelected: false
+selected:        false
+failedISel:      false
+tracksRegLiveness: true
+hasWinCFI:       false
+callsEHReturn:   false
+callsUnwindInit: false
+hasEHCatchret:   false
+hasEHScopes:     false
+hasEHFunclets:   false
+isOutlined:      false
+debugInstrRef:   false
+failsVerification: false
+tracksDebugUserValues: false
+registers:
+  - { id: 0, class: int32regs, preferred-register: '' }
+  - { id: 1, class: int32regs, preferred-register: '' }
+  - { id: 2, class: int32regs, preferred-register: '' }
+  - { id: 3, class: int32regs, preferred-register: '' }
+  - { id: 4, class: int32regs, preferred-register: '' }
+  - { id: 5, class: int32regs, preferred-register: '' }
+  - { id: 6, class: int32regs, preferred-register: '' }
+  - { id: 7, class: int32regs, preferred-register: '' }
+  - { id: 8, class: int32regs, preferred-register: '' }
+  - { id: 9, class: int32regs, preferred-register: '' }
+  - { id: 10, class: int32regs, preferred-register: '' }
+  - { id: 11, class: int32regs, preferred-register: '' }
+liveins:         []
+frameInfo:
+  isFrameAddressTaken: false
+  isReturnAddressTaken: false
+  hasStackMap:     false
+  hasPatchPoint:   false
+  stackSize:       0
+  offsetAdjustment: 0
+  maxAlignment:    1
+  adjustsStack:    false
+  hasCalls:        true
+  stackProtector:  ''
+  functionContext: ''
+  maxCallFrameSize: 4294967295
+  cvBytesOfCalleeSavedRegisters: 0
+  hasOpaqueSPAdjustment: false
+  hasVAStart:      false
+  hasMustTailInVarArgFunc: false
+  hasTailCall:     false
+  isCalleeSavedInfoValid: false
+  localFrameSize:  0
+  savePoint:       ''
+  restorePoint:    ''
+fixedStack:      []
+stack:           []
+entry_values:    []
+callSites:       []
+debugValueSubstitutions: []
+constants:       []
+machineFunctionInfo: {}
+body:             |
+  bb.0:
+    %0:int32regs, %1:int32regs, %2:int32regs, %3:int32regs = LoadParamMemV4I32 0
+    ; CHECK-NOT: ProxyReg
+    %4:int32regs = ProxyRegI32 killed %0
+    %5:int32regs = ProxyRegI32 killed %1
+    %6:int32regs = ProxyRegI32 killed %2
+    %7:int32regs = ProxyRegI32 killed %3
+    ; CHECK: StoreRetvalV4I32 killed %0, killed %1, killed %2, killed %3
+    StoreRetvalV4I32 killed %4, killed %5, killed %6, killed %7, 0
+
+    %8:int32regs = LoadParamMemI32 0
+    ; CHECK-NOT: ProxyReg
+    %9:int32regs = ProxyRegI32 killed %8
+    %10:int32regs = ProxyRegI32 killed %9
+    %11:int32regs = ProxyRegI32 killed %10
+    ; CHECK: StoreRetvalI32 killed %8
+    StoreRetvalI32 killed %11, 0
+    Return
+
+...
diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/proxy-reg-erasure-mir.ll b/llvm/test/CodeGen/NVPTX/proxy-reg-erasure-mir.ll
--- a/llvm/test/CodeGen/NVPTX/proxy-reg-erasure-mir.ll
+++ b/llvm/test/CodeGen/NVPTX/proxy-reg-erasure-mir.ll
@@ -1,25 +0,0 @@
-; RUN: llc -march=nvptx64 -stop-before=nvptx-proxyreg-erasure < %s 2>&1 \
-; RUN:   | FileCheck %s --check-prefix=MIR --check-prefix=MIR-BEFORE
-
-; RUN: llc -march=nvptx64 -stop-after=nvptx-proxyreg-erasure < %s 2>&1 \
-; RUN:   | FileCheck %s --check-prefix=MIR --check-prefix=MIR-AFTER
-
-; Check ProxyRegErasure pass MIR manipulation.
-
-declare <4 x i32> @callee_vec_i32()
-define  <4 x i32> @check_vec_i32() {
-  ; MIR: body:
-  ; MIR-DAG: Callseq_Start {{[0-9]+}}, {{[0-9]+}}
-  ; MIR-DAG: %0:int32regs, %1:int32regs, %2:int32regs, %3:int32regs = LoadParamMemV4I32 0
-  ; MIR-DAG: Callseq_End {{[0-9]+}}
-
-  ; MIR-BEFORE-DAG: %4:int32regs = ProxyRegI32 killed %0
-  ; MIR-BEFORE-DAG: %5:int32regs = ProxyRegI32 killed %1
-  ; MIR-BEFORE-DAG: %6:int32regs = ProxyRegI32 killed %2
-  ; MIR-BEFORE-DAG: %7:int32regs = ProxyRegI32 killed %3
-  ; MIR-BEFORE-DAG: StoreRetvalV4I32 killed %4, killed %5, killed %6, killed %7, 0
-  ; MIR-AFTER-DAG:  StoreRetvalV4I32 killed %0, killed %1, killed %2, killed %3, 0
-
-  %ret = call <4 x i32> @callee_vec_i32()
-  ret <4 x i32> %ret
-}
diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LoadStoreVectorizer/AArch64/pr37865.ll b/llvm/test/Transforms/LoadStoreVectorizer/AArch64/pr37865.ll
--- a/llvm/test/Transforms/LoadStoreVectorizer/AArch64/pr37865.ll
+++ b/llvm/test/Transforms/LoadStoreVectorizer/AArch64/pr37865.ll
@@ -1,22 +1,9 @@
-; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
-; RUN: opt -mtriple=aarch64 -passes=load-store-vectorizer -S %s | FileCheck %s
-
-; LSV was attempting to vectorize this earlier, but crashed while re-ordering
-; instructions due to the load-load cycle. Now, the candidate loads are no
-; longer considered safe for reordering.
+; REQUIRES: asserts
+; RUN: not --crash opt -mtriple=aarch64 -passes=load-store-vectorizer \
+; RUN:   -disable-output %s 2>&1 | FileCheck %s
 
 define i32 @load_cycle(ptr %x) {
-; CHECK-LABEL: define i32 @load_cycle(
-; CHECK-SAME: ptr [[X:%.*]]) {
-; CHECK-NEXT:  [[ENTRY:.*:]]
-; CHECK-NEXT:    [[GEP_X_1:%.*]] = getelementptr inbounds [2 x i32], ptr [[X]], i32 0, i32 1
-; CHECK-NEXT:    [[LOAD_X_1:%.*]] = load i32, ptr [[GEP_X_1]], align 4
-; CHECK-NEXT:    [[REM:%.*]] = urem i32 [[LOAD_X_1]], 1
-; CHECK-NEXT:    [[GEP_X_2:%.*]] = getelementptr inbounds [2 x i32], ptr [[X]], i32 [[REM]], i32 0
-; CHECK-NEXT:    [[LOAD_X_2:%.*]] = load i32, ptr [[GEP_X_2]], align 4
-; CHECK-NEXT:    [[RET:%.*]] = add i32 [[LOAD_X_2]], [[LOAD_X_1]]
-; CHECK-NEXT:    ret i32 [[RET]]
-;
+; CHECK: Unexpected cycle while re-ordering instructions
 entry:
   %gep.x.1 = getelementptr inbounds [2 x i32], ptr %x, i32 0, i32 1
   %load.x.1 = load i32, ptr %gep.x.1
@@ -26,61 +13,3 @@
   %ret = add i32 %load.x.2, %load.x.1
   ret i32 %ret
 }
-
-define i32 @load_cycle2(ptr %x, i32 %y) {
-; CHECK-LABEL: define i32 @load_cycle2(
-; CHECK-SAME: ptr [[X:%.*]], i32 [[Y:%.*]]) {
-; CHECK-NEXT:  [[ENTRY:.*:]]
-; CHECK-NEXT:    [[GEP_X_1:%.*]] = getelementptr inbounds [2 x i32], ptr [[X]], i32 [[Y]], i32 1
-; CHECK-NEXT:    [[LOAD_X_1:%.*]] = load i32, ptr [[GEP_X_1]], align 4
-; CHECK-NEXT:    [[MUL:%.*]] = mul i32 [[LOAD_X_1]], 2
-; CHECK-NEXT:    [[ADD:%.*]] = add i32 [[Y]], [[MUL]]
-; CHECK-NEXT:    [[SUB_1:%.*]] = sub i32 [[ADD]], [[LOAD_X_1]]
-; CHECK-NEXT:    [[SUB_2:%.*]] = sub i32 [[SUB_1]], [[LOAD_X_1]]
-; CHECK-NEXT:    [[GEP_X_2:%.*]] = getelementptr inbounds [2 x i32], ptr [[X]], i32 [[SUB_2]], i32 0
-; CHECK-NEXT:    [[LOAD_X_2:%.*]] = load i32, ptr [[GEP_X_2]], align 4
-; CHECK-NEXT:    [[RET:%.*]] = add i32 [[LOAD_X_2]], [[LOAD_X_1]]
-; CHECK-NEXT:    ret i32 [[RET]]
-;
-entry:
-  %gep.x.1 = getelementptr inbounds [2 x i32], ptr %x, i32 %y, i32 1
-  %load.x.1 = load i32, ptr %gep.x.1
-  %mul = mul i32 %load.x.1, 2
-  %add = add i32 %y, %mul
-  %sub.1 = sub i32 %add, %load.x.1
-  %sub.2 = sub i32 %sub.1, %load.x.1
-  %gep.x.2 = getelementptr inbounds [2 x i32], ptr %x, i32 %sub.2, i32 0
-  %load.x.2 = load i32, ptr %gep.x.2
-  %ret = add i32 %load.x.2, %load.x.1
-  ret i32 %ret
-}
-
-@global.1 = global i32 0
-@global.2 = global [1 x [3 x i32]] zeroinitializer
-
-define i16 @load_cycle3() {
-; CHECK-LABEL: define i16 @load_cycle3() {
-; CHECK-NEXT:  [[ENTRY:.*:]]
-; CHECK-NEXT:    [[LOAD_1:%.*]] = load i32, ptr @global.1, align 4
-; CHECK-NEXT:    [[UREM_1:%.*]] = urem i32 [[LOAD_1]], 1
-; CHECK-NEXT:    [[GEP_1:%.*]] = getelementptr inbounds [1 x [3 x i32]], ptr @global.2, i32 0, i32 [[UREM_1]]
-; CHECK-NEXT:    [[GEP_2:%.*]] = getelementptr inbounds [3 x i32], ptr [[GEP_1]], i32 0, i32 2
-; CHECK-NEXT:    [[LOAD_2:%.*]] = load i32, ptr [[GEP_2]], align 4
-; CHECK-NEXT:    [[UREM_2:%.*]] = urem i32 [[LOAD_2]], 1
-; CHECK-NEXT:    [[GEP_3:%.*]] = getelementptr inbounds [1 x [3 x i32]], ptr @global.2, i32 0, i32 [[UREM_2]]
-; CHECK-NEXT:    [[GEP_4:%.*]] = getelementptr inbounds [3 x i32], ptr [[GEP_3]], i32 0, i32 1
-; CHECK-NEXT:    [[LOAD_3:%.*]] = load i32, ptr [[GEP_4]], align 4
-; CHECK-NEXT:    ret i16 0
-;
-entry:
-  %load.1 = load i32, ptr @global.1
-  %urem.1 = urem i32 %load.1, 1
-  %gep.1 = getelementptr inbounds [1 x [3 x i32]], ptr @global.2, i32 0, i32 %urem.1
-  %gep.2 = getelementptr inbounds [3 x i32], ptr %gep.1, i32 0, i32 2
-  %load.2 = load i32, ptr %gep.2
-  %urem.2 = urem i32 %load.2, 1
-  %gep.3 = getelementptr inbounds [1 x [3 x i32]], ptr @global.2, i32 0, i32 %urem.2
-  %gep.4 = getelementptr inbounds [3 x i32], ptr %gep.3, i32 0, i32 1
-  %load.3 = load i32, ptr %gep.4
-  ret i16 0
-}
