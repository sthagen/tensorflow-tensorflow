// RUN: fusion_to_mlir %s | mlir_fusions_opt -xla-gpu-test-to-inline | FileCheck %s
// RUN: test_correctness %s --bijection_outputs=broadcast

bcast {
  zero = bf16[] constant(0)
  ROOT broadcast = bf16[2,16,48]{2,1,0} broadcast(zero), dimensions={}
}

// CHECK-DAG: #[[MAP0:.*]] = #xla_gpu.indexing_map<(d0, d1) -> (d1 * 1024 + d0)
// CHECK-DAG: #[[MAP1:.*]] = #xla_gpu.indexing_map<(d0, d1) -> ((d1 * 1024 + d0) floordiv 768)
// CHECK-DAG: #[[MAP2:.*]] = #xla_gpu.indexing_map<(d0, d1) -> (((d1 * 1024 + d0) floordiv 48) mod 16)
// CHECK-DAG: #[[MAP3:.*]] = #xla_gpu.indexing_map<(d0, d1) -> ((d1 * 1024 + d0) mod 48)
// CHECK: func.func @main(%[[ARG0:.*]]: tensor<2x16x48xbf16>
// CHECK: %[[UPPER_BOUND:.*]] = arith.constant 1535 : index
// CHECK: %[[THREAD_ID:.*]] = gpu.thread_id
// CHECK: %[[BLOCK_ID:.*]] = gpu.block_id
// CHECK: %[[LINEAR:.*]] = xla_gpu.apply_indexing #[[MAP0]]
// CHECK: %[[IN_BOUNDS:.*]] = arith.cmpi sle, %[[LINEAR]], %[[UPPER_BOUND]] : index
// CHECK: scf.if %[[IN_BOUNDS]]
// CHECK: %[[I0:.*]] = xla_gpu.apply_indexing #[[MAP1]]
// CHECK: %[[I1:.*]] = xla_gpu.apply_indexing #[[MAP2]]
// CHECK: %[[I2:.*]] = xla_gpu.apply_indexing #[[MAP3]]
// CHECK: %[[CST:.*]] = arith.constant 0.000
// CHECK: %[[INSERTED:.*]] = tensor.insert %[[CST]] into %[[ARG0]][%[[I0]], %[[I1]], %[[I2]]]
