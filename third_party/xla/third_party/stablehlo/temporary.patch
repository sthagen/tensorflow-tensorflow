diff --ruN a/stablehlo/stablehlo/dialect/ChloEnums.td b/stablehlo/stablehlo/dialect/ChloEnums.td
--- stablehlo/stablehlo/dialect/ChloEnums.td
+++ stablehlo/stablehlo/dialect/ChloEnums.td
@@ -70,4 +70,29 @@
 
 def CHLO_ComparisonTypeAttr : EnumAttr<CHLO_Dialect, CHLO_ComparisonType, "comparison_type">;
 
+//===----------------------------------------------------------------------===//
+// Ragged dot op definitions.
+//===----------------------------------------------------------------------===//
+
+// These mirror the XLA PrecisionConfig proto enum.
+def CHLO_PRECISION_DEFAULT : I32EnumAttrCase<"DEFAULT", 0>;
+def CHLO_PRECISION_HIGH    : I32EnumAttrCase<"HIGH", 1>;
+def CHLO_PRECISION_HIGHEST : I32EnumAttrCase<"HIGHEST", 2>;
+
+def CHLO_Precision : I32EnumAttr<"Precision",
+    "XLA precision for an operand. Has backend specific meaning.",
+    [
+      CHLO_PRECISION_DEFAULT,
+      CHLO_PRECISION_HIGH,
+      CHLO_PRECISION_HIGHEST
+    ]> {
+  let genSpecializedAttr = 0;
+  let cppNamespace = "::mlir::chlo";
+}
+
+def CHLO_PrecisionAttr : EnumAttr<CHLO_Dialect, CHLO_Precision, "precision">;
+
+def CHLO_PrecisionConfigAttr:
+  TypedArrayAttrBase<CHLO_PrecisionAttr, "Precision Config attribute">;
+
 #endif // STABLEHLO_DIALECT_CHLO_ENUMS
diff --ruN a/stablehlo/stablehlo/dialect/ChloOps.cpp b/stablehlo/stablehlo/dialect/ChloOps.cpp
--- stablehlo/stablehlo/dialect/ChloOps.cpp
+++ stablehlo/stablehlo/dialect/ChloOps.cpp
@@ -42,6 +42,7 @@
 #include "mlir/Support/LogicalResult.h"
 #include "mlir/Support/TypeID.h"
 #include "mlir/Transforms/InliningUtils.h"
+#include "stablehlo/dialect/AssemblyFormat.h"
 #include "stablehlo/dialect/Base.h"
 #include "stablehlo/dialect/BroadcastUtils.h"
 #include "stablehlo/dialect/ChloBytecode.h"
@@ -416,6 +417,242 @@
 }
 
 //===----------------------------------------------------------------------===//
+// RaggedDotOp
+//===----------------------------------------------------------------------===//
+
+namespace {
+
+// RaggedDot has three general modes, based on the kind of the ragged dimension.
+// Mode 1, where the ragged dimension is an lhs non-contracting dim (m).
+//   lhs : [b, m, k]
+//   rhs : [g, b, k, n]
+//   group_sizes : [g]
+//   result : [b, m, n]
+// Mode 2, where the ragged dimension is an lhs/rhs contracting dim (k).
+//   lhs : [b, m, k]
+//   rhs : [b, k, n]
+//   group_sizes : [g]
+//   result : [g, b, m, n]
+// Mode 3, where the ragged dimension is an lhs/rhs batch dim (b).
+//   lhs : [b, m, k]
+//   rhs : [b, k, n]
+//   group_sizes : [g]
+//   result : [b, m, n]
+// As with dot_general, the lhs and rhs can have arbitrary batching,
+// contracting and non-contracting dimensions.
+// Additionally:
+//   - In all modes, the lhs must have exactly one ragged dimension.
+//   - In mode 1, the rhs must have exactly one group dimension.
+LogicalResult checkRaggedDotConstraints(
+    std::optional<Location> location, RankedTensorType rankedLhsType,
+    RankedTensorType rankedRhsType, RankedTensorType rankedGroupSizesType,
+    ArrayRef<int64_t> lhsBatchingDimensions,
+    ArrayRef<int64_t> rhsBatchingDimensions,
+    ArrayRef<int64_t> lhsContractingDimensions,
+    ArrayRef<int64_t> rhsContractingDimensions,
+    ArrayRef<int64_t> lhsRaggedDimensions,
+    ArrayRef<int64_t> rhsGroupDimensions) {
+  // Check that the group sizes has rank=1.
+  if (rankedGroupSizesType.getRank() != 1) {
+    return emitOptionalError(
+        location, "expected rank of group_sizes of ragged dot to be 1, got ",
+        rankedGroupSizesType.getRank());
+  }
+  auto numGroups = rankedGroupSizesType.getDimSize(0);
+
+  // Check that there is exactly one lhs ragged dimension.
+  if (lhsRaggedDimensions.size() != 1) {
+    return emitOptionalError(
+        location, "There must be exactly one ragged dimension in the lhs.");
+  }
+  const int64_t lhsRaggedDim = lhsRaggedDimensions[0];
+
+  // Check that the lhs ragged dimension is in range.
+  if (failed(hlo::checkDimInBounds(location, lhsRaggedDim,
+                                   rankedLhsType.getRank(), "lhs_ragged_dim",
+                                   "lhs_rank"))) {
+    return failure();
+  }
+
+  // Validate basic properties of the rhs group dimension(s).
+  for (auto rhsGroupDim : rhsGroupDimensions) {
+    if (failed(hlo::checkDimInBounds(location, rhsGroupDim,
+                                     rankedRhsType.getRank(), "rhs_group_dim",
+                                     "rhs_rank"))) {
+      return failure();
+    }
+  }
+  if (failed(hlo::checkDimsDistinct(
+          location, rhsGroupDimensions, rhsBatchingDimensions,
+          "rhs_group_dimensions", "rhs_batching_dimensions")) ||
+      failed(hlo::checkDimsDistinct(
+          location, rhsGroupDimensions, rhsContractingDimensions,
+          "rhs_group_dimensions", "rhs_contracting_dimensions"))) {
+    return failure();
+  }
+
+  if (llvm::is_contained(lhsBatchingDimensions, lhsRaggedDim) ||
+      llvm::is_contained(lhsContractingDimensions, lhsRaggedDim)) {
+    // Ragged batch (b):       [b,m,k], [b,k,n], [g] -> [b,m,n].
+    // Ragged contracting (k): [b,m,k], [b,k,n], [g] -> [g,b,m,n].
+    if (!rhsGroupDimensions.empty()) {
+      return emitOptionalError(
+          location,
+          "There must be zero group dimensions in the rhs when the "
+          "ragged dimension is batch or contracting.");
+    }
+  } else {
+    // Ragged non-contracting (m): [b,m,k], [g,b,k,n], [g] -> [b,m,n].
+    if (rhsGroupDimensions.size() != 1) {
+      return emitOptionalError(
+          location,
+          "There must be exactly one group dimension in the rhs when the lhs "
+          "ragged dimension is non-contracting.");
+    }
+    // Compare the group dimension size with the number of groups.
+    const int64_t rhsGroupDim = rhsGroupDimensions[0];
+    if (!hlo::verifyCompatibleDims(numGroups,
+                                   rankedRhsType.getDimSize(rhsGroupDim))) {
+      return emitOptionalError(
+          location, "group_sizes is expected to have shape=[",
+          rankedRhsType.getDimSize(rhsGroupDim), "], got [", numGroups, "]");
+    }
+  }
+  return success();
+}
+
+SmallVector<int64_t> inferRaggedDotOutputDimensions(
+    RankedTensorType rankedLhsType, RankedTensorType rankedRhsType,
+    RankedTensorType rankedGroupSizesType,
+    ArrayRef<int64_t> lhsBatchingDimensions,
+    ArrayRef<int64_t> rhsBatchingDimensions,
+    ArrayRef<int64_t> lhsContractingDimensions,
+    ArrayRef<int64_t> rhsContractingDimensions,
+    ArrayRef<int64_t> lhsRaggedDimensions,
+    ArrayRef<int64_t> rhsGroupDimensions) {
+  // Must have already checked that group_sizes is 1-D.
+  const int64_t numGroups = rankedGroupSizesType.getDimSize(0);
+  // Must have already checked that there is exactly one lhs ragged dim.
+  const int64_t lhsRaggedDim = lhsRaggedDimensions[0];
+
+  SmallVector<int64_t> dimensions;
+  // Add the group dimension to the result shape in case of ragged contracting.
+  if (llvm::is_contained(lhsContractingDimensions, lhsRaggedDim)) {
+    dimensions.push_back(numGroups);
+  }
+  auto lhsShape = rankedLhsType.getShape();
+  auto rhsShape = rankedRhsType.getShape();
+  for (const int64_t lhsBatchingDim : lhsBatchingDimensions)
+    dimensions.push_back(lhsShape[lhsBatchingDim]);
+  for (int64_t i = 0; i < rankedLhsType.getRank(); i++)
+    if (!llvm::is_contained(lhsBatchingDimensions, i) &&
+        !llvm::is_contained(lhsContractingDimensions, i))
+      dimensions.push_back(lhsShape[i]);
+  for (int64_t i = 0; i < rankedRhsType.getRank(); i++)
+    if (!llvm::is_contained(rhsBatchingDimensions, i) &&
+        !llvm::is_contained(rhsContractingDimensions, i) &&
+        !llvm::is_contained(rhsGroupDimensions, i))
+      dimensions.push_back(rhsShape[i]);
+  return dimensions;
+}
+
+LogicalResult inferRaggedDotOp(
+    std::optional<Location> location, Value lhs, Value rhs, Value groupSizes,
+    ArrayRef<int64_t> lhsBatchingDimensions,
+    ArrayRef<int64_t> rhsBatchingDimensions,
+    ArrayRef<int64_t> lhsContractingDimensions,
+    ArrayRef<int64_t> rhsContractingDimensions,
+    ArrayRef<int64_t> lhsRaggedDimensions, ArrayRef<int64_t> rhsGroupDimensions,
+    std::optional<ArrayAttr> precisionConfig,
+    SmallVectorImpl<ShapedTypeComponents>& inferredReturnShapes) {
+  if (failed(hlo::verifyPrecisionConfig(location, precisionConfig))) {
+    return failure();
+  }
+
+  // Validate basic properties of dot dimension numbers.
+  if (failed(hlo::checkDotGeneralConstraints(
+          location, lhs.getType(), rhs.getType(), lhsBatchingDimensions,
+          rhsBatchingDimensions, lhsContractingDimensions,
+          rhsContractingDimensions, precisionConfig))) {
+    return failure();
+  }
+
+  // Validate ragged dot constraints.
+  auto rankedLhsType = cast<RankedTensorType>(lhs.getType());
+  auto rankedRhsType = cast<RankedTensorType>(rhs.getType());
+  auto rankedGroupSizesType = cast<RankedTensorType>(groupSizes.getType());
+  if (failed(checkRaggedDotConstraints(
+          location, rankedLhsType, rankedRhsType, rankedGroupSizesType,
+          lhsBatchingDimensions, rhsBatchingDimensions,
+          lhsContractingDimensions, rhsContractingDimensions,
+          lhsRaggedDimensions, rhsGroupDimensions))) {
+    return failure();
+  }
+
+  // Infer the output dimensions of the ragged dot operation.
+  inferredReturnShapes.emplace_back(inferRaggedDotOutputDimensions(
+      rankedLhsType, rankedRhsType, rankedGroupSizesType, lhsBatchingDimensions,
+      rhsBatchingDimensions, lhsContractingDimensions, rhsContractingDimensions,
+      lhsRaggedDimensions, rhsGroupDimensions));
+  return success();
+}
+
+}  // namespace
+
+LogicalResult RaggedDotOp::verify() {
+  auto location = getLoc();
+  auto raggedDotDimNums = getRaggedDotDimensionNumbers();
+
+  SmallVector<ShapedTypeComponents> inferredReturnShapes;
+  if (failed(inferRaggedDotOp(location, getLhs(), getRhs(), getGroupSizes(),
+                              raggedDotDimNums.getLhsBatchingDimensions(),
+                              raggedDotDimNums.getRhsBatchingDimensions(),
+                              raggedDotDimNums.getLhsContractingDimensions(),
+                              raggedDotDimNums.getRhsContractingDimensions(),
+                              raggedDotDimNums.getLhsRaggedDimensions(),
+                              raggedDotDimNums.getRhsGroupDimensions(),
+                              getPrecisionConfig(), inferredReturnShapes)))
+    return failure();
+  auto inferredShape = inferredReturnShapes[0];
+
+  auto resultType = cast<ShapedType>(getResult().getType());
+  if (failed(verifyCompatibleShape(inferredShape.getDims(),
+                                   resultType.getShape()))) {
+    return emitOptionalError(
+        location, "inferred shape '",
+        hlo::dimSizesToString(inferredShape.getDims()), "' ",
+        "is incompatible with return type of operation ", resultType, "");
+  }
+
+  return success();
+}
+
+LogicalResult RaggedDotOp::inferReturnTypes(
+    MLIRContext*, std::optional<Location>, ValueRange operands,
+    DictionaryAttr attributes, OpaqueProperties properties, RegionRange regions,
+    SmallVectorImpl<Type>& inferredReturnTypes) {
+  RaggedDotOp::Adaptor op(operands, attributes, properties, regions);
+
+  auto rankedLhsType = cast<RankedTensorType>(op.getLhs().getType());
+  auto rankedRhsType = cast<RankedTensorType>(op.getRhs().getType());
+  auto rankedGroupSizesType =
+      cast<RankedTensorType>(op.getGroupSizes().getType());
+  auto raggedDotDimNums = op.getRaggedDotDimensionNumbers();
+
+  inferredReturnTypes.push_back(RankedTensorType::get(
+      inferRaggedDotOutputDimensions(
+          rankedLhsType, rankedRhsType, rankedGroupSizesType,
+          raggedDotDimNums.getLhsBatchingDimensions(),
+          raggedDotDimNums.getRhsBatchingDimensions(),
+          raggedDotDimNums.getLhsContractingDimensions(),
+          raggedDotDimNums.getRhsContractingDimensions(),
+          raggedDotDimNums.getLhsRaggedDimensions(),
+          raggedDotDimNums.getRhsGroupDimensions()),
+      rankedLhsType.getElementType()));
+  return success();
+}
+
+//===----------------------------------------------------------------------===//
 // TopKOp
 //===----------------------------------------------------------------------===//
 
@@ -523,5 +760,140 @@
   assert(succeeded(result));
 }
 
+/// Helpers for attributes parsing.
+
+static ParseResult parseDims(AsmParser& parser,
+                             SmallVector<int64_t>& dimSizes) {
+  dimSizes.clear();
+  auto failOrDims = hlo::parseDimSizes(parser);
+  if (failed(failOrDims)) return failure();
+  dimSizes = std::move(*failOrDims);
+  return success();
+}
+
+/// Parse a custom attribute that resembles a struct of the form
+/// <
+///   foo = something_parsed_by_custom_parser,
+///   bar = something_parsed_by_different_custom_parser,
+///   baz something_parsed_by_another_custom_parser
+/// >
+/// The optional argument `parse_equal` array can be used to denote if
+/// '=' follows the keyword (see baz in the example above) for a field. If
+/// not provided, all fields must be followed by a '='.
+static ParseResult parseStruct(
+    AsmParser& parser, ArrayRef<StringRef> keywords,
+    ArrayRef<llvm::function_ref<ParseResult()>> parseFuncs,
+    ArrayRef<bool> parseEqual = {}) {
+  assert(keywords.size() == parseFuncs.size());
+  assert(parseEqual.empty() || parseEqual.size() == keywords.size());
+  SmallVector<bool> seen(keywords.size(), false);
+  while (failed(parser.parseOptionalGreater())) {
+    bool foundOne = false;
+    for (const auto& it : llvm::enumerate(keywords)) {
+      size_t index = it.index();
+      StringRef keyword = it.value();
+      if (failed(parser.parseOptionalKeyword(keyword))) continue;
+      if (seen[index])
+        return parser.emitError(parser.getCurrentLocation())
+               << "duplicated `" << keyword << "` entry";
+      if (parseEqual.empty() || parseEqual[index]) {
+        if (failed(parser.parseEqual())) return failure();
+      }
+      if (failed(parseFuncs[index]())) return failure();
+      if (failed(parser.parseOptionalComma())) return parser.parseGreater();
+      seen[index] = true;
+      foundOne = true;
+    }
+    if (!foundOne) {
+      auto parseError = parser.emitError(parser.getCurrentLocation())
+                        << "expected one of: ";
+      llvm::interleaveComma(keywords, parseError, [&](StringRef kw) {
+        parseError << '`' << kw << '`';
+      });
+      return parseError;
+    }
+  }
+  return success();
+}
+
+// Helpers to print an optional array or integer field, to simplify writing
+// attribute printers.
+template <typename T>
+static void printField(AsmPrinter& printer, StringRef name, T field,
+                       StringRef& separator) {
+  if (field != 0) {
+    printer << separator << name << " = " << field;
+    separator = ", ";
+  }
+}
+template <typename T>
+static void printField(AsmPrinter& printer, StringRef name, ArrayRef<T> field,
+                       StringRef& separator) {
+  if (!field.empty()) {
+    printer << separator << name << " = [";
+    llvm::interleaveComma(field, printer);
+    printer << "]";
+    separator = ", ";
+  }
+}
+template <typename... Ts>
+static void printStruct(AsmPrinter& printer, StringRef name,
+                        Ts... printFields) {
+  printer << "<";
+  StringRef separator = "";
+  // Fold expression to print each entry in the parameter pack.
+  // TODO(stablehlo-team): this can be simplified when TF moves to C++17.
+  using unused = int[];
+  (void)unused{0, (printField(printer, std::get<0>(printFields),
+                              std::get<1>(printFields), separator),
+                   0)...};
+  printer << ">";
+}
+
+// Custom printer and parser for RaggedDotDimensionNumbersAttr.
+void RaggedDotDimensionNumbersAttr::print(AsmPrinter& printer) const {
+  printStruct(
+      printer, "ragged_dot",
+      std::make_pair("lhs_batching_dimensions", getLhsBatchingDimensions()),
+      std::make_pair("rhs_batching_dimensions", getRhsBatchingDimensions()),
+      std::make_pair("lhs_contracting_dimensions",
+                     getLhsContractingDimensions()),
+      std::make_pair("rhs_contracting_dimensions",
+                     getRhsContractingDimensions()),
+      std::make_pair("lhs_ragged_dimensions", getLhsRaggedDimensions()),
+      std::make_pair("rhs_group_dimensions", getRhsGroupDimensions()));
+}
+
+Attribute RaggedDotDimensionNumbersAttr::parse(AsmParser& parser, Type type) {
+  if (failed(parser.parseLess())) return {};
+
+  SmallVector<int64_t> lhsBatchingDimensions;
+  SmallVector<int64_t> rhsBatchingDimensions;
+  SmallVector<int64_t> lhsContractingDimensions;
+  SmallVector<int64_t> rhsContractingDimensions;
+  SmallVector<int64_t> lhsRaggedDimensions;
+  SmallVector<int64_t> rhsGroupDimensions;
+
+  if (failed(parseStruct(
+          parser,
+          {"lhs_batching_dimensions", "rhs_batching_dimensions",
+           "lhs_contracting_dimensions", "rhs_contracting_dimensions",
+           "lhs_ragged_dimensions", "rhs_group_dimensions"},
+          {[&]() { return parseDims(parser, lhsBatchingDimensions); },
+           [&]() { return parseDims(parser, rhsBatchingDimensions); },
+           [&]() { return parseDims(parser, lhsContractingDimensions); },
+           [&]() { return parseDims(parser, rhsContractingDimensions); },
+           [&]() { return parseDims(parser, lhsRaggedDimensions); },
+           [&]() { return parseDims(parser, rhsGroupDimensions); }}))) {
+    parser.emitError(parser.getCurrentLocation())
+        << "failed parsing ragged dot dimension numbers attribute";
+    return {};
+  }
+  return RaggedDotDimensionNumbersAttr::get(
+      parser.getContext(), lhsBatchingDimensions, rhsBatchingDimensions,
+      lhsContractingDimensions, rhsContractingDimensions, lhsRaggedDimensions,
+      rhsGroupDimensions);
+}
+
 }  // namespace chlo
 }  // namespace mlir
diff --ruN a/stablehlo/stablehlo/dialect/ChloOps.td b/stablehlo/stablehlo/dialect/ChloOps.td
--- stablehlo/stablehlo/dialect/ChloOps.td
+++ stablehlo/stablehlo/dialect/ChloOps.td
@@ -834,6 +834,67 @@
 }
 
 //===----------------------------------------------------------------------===//
+// Ragged dot op
+//===----------------------------------------------------------------------===//
+
+def CHLO_Dims : ArrayRefParameter<"int64_t", "Dimension"> {
+  let parser = "parseDimSizes($_parser)";
+  let printer = "printDimSizes($_printer, $_self)";
+}
+
+def CHLO_RaggedDotDimensionNumbers : AttrDef<CHLO_Dialect, "RaggedDotDimensionNumbers"> {
+  let mnemonic = "ragged_dot";
+  let summary = "Attribute that models the dimension information for ragged dot.";
+  let parameters = (ins
+      CHLO_Dims:$lhsBatchingDimensions,
+      CHLO_Dims:$rhsBatchingDimensions,
+      CHLO_Dims:$lhsContractingDimensions,
+      CHLO_Dims:$rhsContractingDimensions,
+      CHLO_Dims:$lhsRaggedDimensions,
+      CHLO_Dims:$rhsGroupDimensions
+  );
+  let hasCustomAssemblyFormat = 1;
+}
+
+def CHLO_RaggedDotOp : CHLO_Op<"ragged_dot",
+    [Pure, DeclareOpInterfaceMethods<InferTypeOpInterface>]> {
+  string summary = "Computes a matmul over a single ragged dimension";
+
+  string description = [{
+
+    This operation takes three tensor args---lhs, rhs, and group_sizes---and
+    a "ragged_dot_dimension_numbers" attribute. Like dot_general, the lhs and
+    rhs are allowed arbitrary batch and contracting dimensions. Additionally,
+    the lhs is required to have one ragged dimension, and the rhs may have at
+    most one group dimension. The op has three modes, depending on the kind of
+    the lhs ragged dimension.
+
+    In mode 1, the shape-signature is `[b,m,k], [g,b,k,n], [g] -> [b,m,n]`.
+    Here the ragged dimension is an lhs non-contracting dimension (`m`). The
+    dimensions `b` and `k` represent batch and contracting dimensions
+    respectively. The rhs is required to have a group dimension (`g`).
+
+    In mode 2, the shape-signature is `[b,m,k], [b,k,n], [g] -> [g,b,m,n]`.
+    Here the ragged dimension is an lhs/rhs contracting dimension (`k`).
+
+    In mode 3, the shape-signature is `[b,m,k], [b,k,n], [g] -> [b,m,n]`. Here
+    the ragged dimension is an lhs/rhs batch dimension (`b`).
+
+   }];
+
+  let arguments = (ins
+    HLO_AnyTensor:$lhs,
+    HLO_AnyTensor:$rhs,
+    Arg<HLO_IntTensor, [{A g-shaped array indicating the size of each group}]>:$group_sizes,
+    CHLO_RaggedDotDimensionNumbers:$ragged_dot_dimension_numbers,
+    OptionalAttr<CHLO_PrecisionConfigAttr>:$precision_config
+  );
+
+  let results = (outs HLO_AnyTensor:$result);
+  let hasVerifier = 1;
+}
+
+//===----------------------------------------------------------------------===//
 // Miscellaneous ops
 //===----------------------------------------------------------------------===//
 
diff --ruN a/stablehlo/stablehlo/integrations/python/CheckModule.cpp b/stablehlo/stablehlo/integrations/python/CheckModule.cpp
--- stablehlo/stablehlo/integrations/python/CheckModule.cpp
+++ stablehlo/stablehlo/integrations/python/CheckModule.cpp
@@ -11,12 +11,13 @@
 ==============================================================================*/
 
 #include "mlir-c/IR.h"
-#include "mlir/Bindings/Python/PybindAdaptors.h"
+#include "mlir/Bindings/Python/NanobindAdaptors.h"
+#include "nanobind/nanobind.h"
 #include "stablehlo/integrations/c/CheckDialect.h"
 
-namespace py = pybind11;
+namespace nb = nanobind;
 
-PYBIND11_MODULE(_check, m) {
+NB_MODULE(_check, m) {
   m.doc() = "check main python extension";
 
   //
@@ -32,5 +33,5 @@
           mlirDialectHandleLoadDialect(dialect, context);
         }
       },
-      py::arg("context"), py::arg("load") = true);
+      nb::arg("context"), nb::arg("load") = true);
 }
diff --ruN a/stablehlo/stablehlo/integrations/python/ChloModule.cpp b/stablehlo/stablehlo/integrations/python/ChloModule.cpp
--- stablehlo/stablehlo/integrations/python/ChloModule.cpp
+++ stablehlo/stablehlo/integrations/python/ChloModule.cpp
@@ -12,21 +12,23 @@
 ==============================================================================*/
 
 #include "mlir-c/IR.h"
-#include "mlir/Bindings/Python/PybindAdaptors.h"
+#include "mlir/Bindings/Python/NanobindAdaptors.h"
+#include "nanobind/nanobind.h"
+#include "nanobind/stl/string_view.h"
 #include "stablehlo/integrations/c/ChloAttributes.h"
 #include "stablehlo/integrations/c/ChloDialect.h"
 
-namespace py = pybind11;
+namespace nb = nanobind;
 
 namespace {
 
 auto toPyString(MlirStringRef mlirStringRef) {
-  return py::str(mlirStringRef.data, mlirStringRef.length);
+  return nb::str(mlirStringRef.data, mlirStringRef.length);
 }
 
 }  // namespace
 
-PYBIND11_MODULE(_chlo, m) {
+NB_MODULE(_chlo, m) {
   m.doc() = "chlo main python extension";
 
   //
@@ -42,35 +44,37 @@
           mlirDialectHandleLoadDialect(dialect, context);
         }
       },
-      py::arg("context"), py::arg("load") = true);
+      nb::arg("context"), nb::arg("load") = true);
 
   //
   // Attributes.
   //
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ComparisonDirectionAttr", chloAttributeIsAComparisonDirectionAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, std::string_view value, MlirContext ctx) {
             return cls(chloComparisonDirectionAttrGet(
-                ctx, mlirStringRefCreate(value.c_str(), value.size())));
+                ctx, mlirStringRefCreate(value.data(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a ComparisonDirection attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(chloComparisonDirectionAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ComparisonTypeAttr", chloAttributeIsAComparisonTypeAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, std::string_view value, MlirContext ctx) {
             return cls(chloComparisonTypeAttrGet(
-                ctx, mlirStringRefCreate(value.c_str(), value.size())));
+                ctx, mlirStringRefCreate(value.data(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a ComparisonType attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(chloComparisonTypeAttrGetValue(self));
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloApi.cpp b/stablehlo/stablehlo/integrations/python/StablehloApi.cpp
--- stablehlo/stablehlo/integrations/python/StablehloApi.cpp
+++ stablehlo/stablehlo/integrations/python/StablehloApi.cpp
@@ -15,6 +15,7 @@
 
 #include "stablehlo/integrations/python/StablehloApi.h"
 
+#include <stdexcept>
 #include <string>
 #include <string_view>
 
@@ -22,10 +23,14 @@
 #include "mlir-c/BuiltinAttributes.h"
 #include "mlir-c/IR.h"
 #include "mlir-c/Support.h"
-#include "mlir/Bindings/Python/PybindAdaptors.h"
+#include "mlir/Bindings/Python/NanobindAdaptors.h"
+#include "nanobind/nanobind.h"
+#include "nanobind/stl/string.h"
+#include "nanobind/stl/string_view.h"
+#include "nanobind/stl/vector.h"
 #include "stablehlo/integrations/c/StablehloApi.h"
 
-namespace py = pybind11;
+namespace nb = nanobind;
 
 namespace mlir {
 namespace stablehlo {
@@ -63,14 +68,18 @@
   return mlirStringRefCreate(s.data(), s.size());
 }
 
-void AddStablehloApi(py::module &m) {
+static MlirStringRef toMlirStringRef(const nb::bytes &s) {
+  return mlirStringRefCreate(static_cast<const char *>(s.data()), s.size());
+}
+
+void AddStablehloApi(nb::module_ &m) {
   // Portable API is a subset of StableHLO API
   AddPortableApi(m);
 
   //
   // Utility APIs.
   //
-  py::enum_<MlirStablehloCompatibilityRequirement>(
+  nb::enum_<MlirStablehloCompatibilityRequirement>(
       m, "StablehloCompatibilityRequirement")
       .value("NONE", MlirStablehloCompatibilityRequirement::NONE)
       .value("WEEK_4", MlirStablehloCompatibilityRequirement::WEEK_4)
@@ -79,34 +88,34 @@
 
   m.def(
       "get_version_from_compatibility_requirement",
-      [](MlirStablehloCompatibilityRequirement requirement) -> py::str {
+      [](MlirStablehloCompatibilityRequirement requirement) -> std::string {
         StringWriterHelper accumulator;
         stablehloVersionFromCompatibilityRequirement(
             requirement, accumulator.getMlirStringCallback(),
             accumulator.getUserData());
         return accumulator.toString();
       },
-      py::arg("requirement"));
+      nb::arg("requirement"));
 
   //
   // Serialization APIs.
   //
   m.def(
       "serialize_portable_artifact",
-      [](MlirModule module, std::string_view target) -> py::bytes {
+      [](MlirModule module, std::string_view target) -> nb::bytes {
         StringWriterHelper accumulator;
         if (mlirLogicalResultIsFailure(
                 stablehloSerializePortableArtifactFromModule(
                     module, toMlirStringRef(target),
                     accumulator.getMlirStringCallback(),
                     accumulator.getUserData()))) {
-          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
-          return "";
-        }
-
-        return py::bytes(accumulator.toString());
-      },
-      py::arg("module"), py::arg("target"));
+          throw nb::value_error("failed to serialize module");
+        }
+
+        std::string serialized = accumulator.toString();
+        return nb::bytes(serialized.data(), serialized.size());
+      },
+      nb::arg("module"), nb::arg("target"));
 
   m.def(
       "deserialize_portable_artifact",
@@ -114,13 +123,22 @@
         auto module = stablehloDeserializePortableArtifactNoError(
             toMlirStringRef(artifact), context);
         if (mlirModuleIsNull(module)) {
-          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
-          return {};
+          throw nb::value_error("failed to deserialize module");
         }
         return module;
       },
-      py::arg("context"), py::arg("artifact"));
-
+      nb::arg("context"), nb::arg("artifact"));
+  m.def(
+      "deserialize_portable_artifact",
+      [](MlirContext context, nb::bytes artifact) -> MlirModule {
+        auto module = stablehloDeserializePortableArtifactNoError(
+            toMlirStringRef(artifact), context);
+        if (mlirModuleIsNull(module)) {
+          throw nb::value_error("failed to deserialize module");
+        }
+        return module;
+      },
+      nb::arg("context"), nb::arg("artifact"));
   //
   // Reference APIs
   //
@@ -130,9 +148,7 @@
          std::vector<MlirAttribute> &args) -> std::vector<MlirAttribute> {
         for (auto arg : args) {
           if (!mlirAttributeIsADenseElements(arg)) {
-            PyErr_SetString(PyExc_ValueError,
-                            "input args must be DenseElementsAttr");
-            return {};
+            throw nb::value_error("input args must be DenseElementsAttr");
           }
         }
 
@@ -141,8 +157,7 @@
             stablehloEvalModule(module, args.size(), args.data(), &errorCode);
 
         if (errorCode != 0) {
-          PyErr_SetString(PyExc_ValueError, "interpreter failed");
-          return {};
+          throw nb::value_error("interpreter failed");
         }
 
         std::vector<MlirAttribute> pyResults;
@@ -151,10 +166,10 @@
         }
         return pyResults;
       },
-      py::arg("module"), py::arg("args"));
-}
-
-void AddPortableApi(py::module &m) {
+      nb::arg("module"), nb::arg("args"));
+}
+
+void AddPortableApi(nb::module_ &m) {
   //
   // Utility APIs.
   //
@@ -162,28 +177,28 @@
 
   m.def(
       "get_smaller_version",
-      [](const std::string &version1, const std::string &version2) -> py::str {
+      [](const std::string &version1,
+         const std::string &version2) -> std::string {
         StringWriterHelper accumulator;
         if (mlirLogicalResultIsFailure(stablehloGetSmallerVersion(
                 toMlirStringRef(version1), toMlirStringRef(version2),
                 accumulator.getMlirStringCallback(),
                 accumulator.getUserData()))) {
-          PyErr_SetString(PyExc_ValueError,
-                          "failed to convert version to stablehlo version");
-          return "";
+          throw nb::value_error(
+              "failed to convert version to stablehlo version");
         }
         return accumulator.toString();
       },
-      py::arg("version1"), py::arg("version2"));
-
-  m.def("get_current_version", []() -> py::str {
+      nb::arg("version1"), nb::arg("version2"));
+
+  m.def("get_current_version", []() -> std::string {
     StringWriterHelper accumulator;
     stablehloGetCurrentVersion(accumulator.getMlirStringCallback(),
                                accumulator.getUserData());
     return accumulator.toString();
   });
 
-  m.def("get_minimum_version", []() -> py::str {
+  m.def("get_minimum_version", []() -> std::string {
     StringWriterHelper accumulator;
     stablehloGetMinimumVersion(accumulator.getMlirStringCallback(),
                                accumulator.getUserData());
@@ -196,7 +211,7 @@
   m.def(
       "serialize_portable_artifact_str",
       [](std::string_view moduleStrOrBytecode,
-         std::string_view targetVersion) -> py::bytes {
+         std::string_view targetVersion) -> nb::bytes {
         StringWriterHelper accumulator;
         if (mlirLogicalResultIsFailure(
                 stablehloSerializePortableArtifactFromStringRef(
@@ -204,26 +219,56 @@
                     toMlirStringRef(targetVersion),
                     accumulator.getMlirStringCallback(),
                     accumulator.getUserData()))) {
-          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
-          return "";
-        }
-        return py::bytes(accumulator.toString());
-      },
-      py::arg("module_str"), py::arg("target_version"));
+          throw nb::value_error("failed to serialize module");
+        }
+        std::string serialized = accumulator.toString();
+        return nb::bytes(serialized.data(), serialized.size());
+      },
+      nb::arg("module_str"), nb::arg("target_version"));
+  m.def(
+      "serialize_portable_artifact_str",
+      [](nb::bytes moduleStrOrBytecode,
+         std::string_view targetVersion) -> nb::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(
+                stablehloSerializePortableArtifactFromStringRef(
+                    toMlirStringRef(moduleStrOrBytecode),
+                    toMlirStringRef(targetVersion),
+                    accumulator.getMlirStringCallback(),
+                    accumulator.getUserData()))) {
+          throw nb::value_error("failed to serialize module");
+        }
+        std::string serialized = accumulator.toString();
+        return nb::bytes(serialized.data(), serialized.size());
+      },
+      nb::arg("module_str"), nb::arg("target_version"));
 
   m.def(
       "deserialize_portable_artifact_str",
-      [](std::string_view artifact) -> py::bytes {
+      [](std::string_view artifact) -> nb::bytes {
         StringWriterHelper accumulator;
         if (mlirLogicalResultIsFailure(stablehloDeserializePortableArtifact(
                 toMlirStringRef(artifact), accumulator.getMlirStringCallback(),
                 accumulator.getUserData()))) {
-          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
-          return "";
-        }
-        return py::bytes(accumulator.toString());
-      },
-      py::arg("artifact_str"));
+          throw nb::value_error("failed to deserialize module");
+        }
+        std::string serialized = accumulator.toString();
+        return nb::bytes(serialized.data(), serialized.size());
+      },
+      nb::arg("artifact_str"));
+  m.def(
+      "deserialize_portable_artifact_str",
+      [](const nb::bytes& artifact) -> nb::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloDeserializePortableArtifact(
+                toMlirStringRef(artifact), accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          throw nb::value_error("failed to deserialize module");
+        }
+        std::string serialized = accumulator.toString();
+        return nb::bytes(serialized.data(), serialized.size());
+      },
+      nb::arg("artifact_str"));
 }
 
 }  // namespace stablehlo
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloApi.h b/stablehlo/stablehlo/integrations/python/StablehloApi.h
--- stablehlo/stablehlo/integrations/python/StablehloApi.h
+++ stablehlo/stablehlo/integrations/python/StablehloApi.h
@@ -16,20 +16,20 @@
 #ifndef STABLEHLO_INTEGRATIONS_PYTHON_API_STABLEHLOAPI_H
 #define STABLEHLO_INTEGRATIONS_PYTHON_API_STABLEHLOAPI_H
 
-#include "pybind11/pybind11.h"
+#include "nanobind/nanobind.h"
 
 namespace mlir {
 namespace stablehlo {
 
-// Add StableHLO APIs to the pybind11 module.
+// Add StableHLO APIs to the nanobind module.
 // Signatures of these APIs have no dependency on C++ MLIR types and all must
 // use C API passthrough.
-void AddStablehloApi(pybind11::module& m);
+void AddStablehloApi(nanobind::module_& m);
 
 // Adds a subset of the StableHLO API that doesn't use MLIR in any definitions,
 // and is methods only, introducing no new objects / enums to avoid potential
 // redefinition issues in complex build environments.
-void AddPortableApi(pybind11::module& m);
+void AddPortableApi(nanobind::module_& m);
 
 }  // namespace stablehlo
 }  // namespace mlir
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloModule.cpp b/stablehlo/stablehlo/integrations/python/StablehloModule.cpp
--- stablehlo/stablehlo/integrations/python/StablehloModule.cpp
+++ stablehlo/stablehlo/integrations/python/StablehloModule.cpp
@@ -15,14 +15,17 @@
 
 #include "mlir-c/IR.h"
 #include "mlir-c/Support.h"
-#include "mlir/Bindings/Python/PybindAdaptors.h"
+#include "mlir/Bindings/Python/NanobindAdaptors.h"
+#include "nanobind/nanobind.h"
+#include "nanobind/stl/string.h"
+#include "nanobind/stl/vector.h"
 #include "stablehlo/integrations/c/StablehloAttributes.h"
 #include "stablehlo/integrations/c/StablehloDialect.h"
 #include "stablehlo/integrations/c/StablehloPasses.h"
 #include "stablehlo/integrations/c/StablehloTypes.h"
 #include "stablehlo/integrations/python/StablehloApi.h"
 
-namespace py = pybind11;
+namespace nb = nanobind;
 
 namespace {
 // Returns a vector containing integers extracted from an attribute using the
@@ -40,12 +43,12 @@
 }
 
 auto toPyString(MlirStringRef mlirStringRef) {
-  return py::str(mlirStringRef.data, mlirStringRef.length);
+  return nb::str(mlirStringRef.data, mlirStringRef.length);
 }
 
 }  // namespace
 
-PYBIND11_MODULE(_stablehlo, m) {
+NB_MODULE(_stablehlo, m) {
   m.doc() = "stablehlo main python extension";
 
   //
@@ -61,7 +64,7 @@
           mlirDialectHandleLoadDialect(dialect, context);
         }
       },
-      py::arg("context"), py::arg("load") = true);
+      nb::arg("context"), nb::arg("load") = true);
 
   //
   // Passes.
@@ -74,14 +77,14 @@
   // Types.
   //
 
-  mlir::python::adaptors::mlir_type_subclass(m, "TokenType",
-                                             stablehloTypeIsAToken)
-      .def_classmethod(
-          "get",
-          [](py::object cls, MlirContext ctx) {
+  mlir::python::nanobind_adaptors::mlir_type_subclass(m, "TokenType",
+                                                      stablehloTypeIsAToken)
+      .def_classmethod(
+          "get",
+          [](nb::object cls, MlirContext ctx) {
             return cls(stablehloTokenTypeGet(ctx));
           },
-          py::arg("cls"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("context").none() = nb::none(),
           "Creates a Token type.");
 
   //
@@ -94,12 +97,12 @@
         stablehloScatterDimensionNumbersGetScatteredDimsToOperandDimsElem);
   };
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ScatterDimensionNumbers",
       stablehloAttributeIsAScatterDimensionNumbers)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::vector<int64_t> &updateWindowDims,
+          [](nb::object cls, const std::vector<int64_t> &updateWindowDims,
              const std::vector<int64_t> &insertedWindowDims,
              const std::vector<int64_t> &inputBatchingDims,
              const std::vector<int64_t> &scatterIndicesBatchingDims,
@@ -114,11 +117,11 @@
                 scatteredDimsToOperandDims.size(),
                 scatteredDimsToOperandDims.data(), indexVectorDim));
           },
-          py::arg("cls"), py::arg("update_window_dims"),
-          py::arg("inserted_window_dims"), py::arg("input_batching_dims"),
-          py::arg("scatter_indices_batching_dims"),
-          py::arg("scattered_dims_to_operand_dims"),
-          py::arg("index_vector_dim"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("update_window_dims"),
+          nb::arg("inserted_window_dims"), nb::arg("input_batching_dims"),
+          nb::arg("scatter_indices_batching_dims"),
+          nb::arg("scattered_dims_to_operand_dims"),
+          nb::arg("index_vector_dim"), nb::arg("context").none() = nb::none(),
           "Creates a ScatterDimensionNumbers with the given dimension "
           "configuration.")
       .def_property_readonly(
@@ -156,11 +159,11 @@
         return stablehloDimensionNumbersGetIndexVectorDim(self);
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "GatherDimensionNumbers", stablehloAttributeIsAGatherDimensionNumbers)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::vector<int64_t> &offsetDims,
+          [](nb::object cls, const std::vector<int64_t> &offsetDims,
              const std::vector<int64_t> &collapsedSliceDims,
              const std::vector<int64_t> &operandBatchingDims,
              const std::vector<int64_t> &startIndicesBatchingDims,
@@ -174,10 +177,10 @@
                 startIndicesBatchingDims.data(), startIndexMap.size(),
                 startIndexMap.data(), indexVectorDim));
           },
-          py::arg("cls"), py::arg("offset_dims"),
-          py::arg("collapsed_slice_dims"), py::arg("operand_batching_dims"),
-          py::arg("start_indices_batching_dims"), py::arg("start_index_map"),
-          py::arg("index_vector_dim"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("offset_dims"),
+          nb::arg("collapsed_slice_dims"), nb::arg("operand_batching_dims"),
+          nb::arg("start_indices_batching_dims"), nb::arg("start_index_map"),
+          nb::arg("index_vector_dim"), nb::arg("context").none() = nb::none(),
           "Creates a GatherDimensionNumbers attribute with the given dimension "
           "configuration.")
       .def_property_readonly(
@@ -220,11 +223,11 @@
         return stablehloGatherDimensionNumbersGetIndexVectorDim(self);
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "DotAlgorithm", stablehloAttributeIsADotAlgorithm)
       .def_classmethod(
           "get",
-          [](py::object cls, MlirType lhsPrecisionType,
+          [](nb::object cls, MlirType lhsPrecisionType,
              MlirType rhsPrecisionType, MlirType accumulationType,
              int64_t lhsComponentCount, int64_t rhsComponentCount,
              int64_t numPrimitiveOperations, bool allowImpreciseAccumulation,
@@ -234,11 +237,12 @@
                 lhsComponentCount, rhsComponentCount, numPrimitiveOperations,
                 allowImpreciseAccumulation));
           },
-          py::arg("cls"), py::arg("lhs_precision_type"),
-          py::arg("rhs_precision_type"), py::arg("accumulation_type"),
-          py::arg("lhs_component_count"), py::arg("rhs_component_count"),
-          py::arg("num_primitive_operations"),
-          py::arg("allow_imprecise_accumulation"), py::arg("ctx") = py::none(),
+          nb::arg("cls"), nb::arg("lhs_precision_type"),
+          nb::arg("rhs_precision_type"), nb::arg("accumulation_type"),
+          nb::arg("lhs_component_count"), nb::arg("rhs_component_count"),
+          nb::arg("num_primitive_operations"),
+          nb::arg("allow_imprecise_accumulation"),
+          nb::arg("ctx").none() = nb::none(),
           "Creates a DotAlgorithm attribute with the given dimension "
           "configuration.")
       .def_property_readonly(
@@ -276,11 +280,11 @@
             return stablehloDotAlgorithmGetAllowImpreciseAccumulation(self);
           });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "DotDimensionNumbers", stablehloAttributeIsADotDimensionNumbers)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::vector<int64_t> &lhsBatchingDims,
+          [](nb::object cls, const std::vector<int64_t> &lhsBatchingDims,
              const std::vector<int64_t> &rhsBatchingDims,
              const std::vector<int64_t> &lhsContractingDims,
              const std::vector<int64_t> &rhsContractingDims, MlirContext ctx) {
@@ -290,11 +294,11 @@
                 lhsContractingDims.size(), lhsContractingDims.data(),
                 rhsContractingDims.size(), rhsContractingDims.data()));
           },
-          py::arg("cls"), py::arg("lhs_batching_dimensions"),
-          py::arg("rhs_batching_dimensions"),
-          py::arg("lhs_contracting_dimensions"),
-          py::arg("rhs_contracting_dimensions"),
-          py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("lhs_batching_dimensions"),
+          nb::arg("rhs_batching_dimensions"),
+          nb::arg("lhs_contracting_dimensions"),
+          nb::arg("rhs_contracting_dimensions"),
+          nb::arg("context").none() = nb::none(),
           "Creates a DotDimensionNumbers attribute with the given dimension "
           "configuration.")
       .def_property_readonly(
@@ -327,11 +331,11 @@
                 stablehloDotDimensionNumbersGetRhsContractingDimensionsElem);
           });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ConvDimensionNumbers", stablehloAttributeIsAConvDimensionNumbers)
       .def_classmethod(
           "get",
-          [](py::object cls, int64_t inputBatchDimension,
+          [](nb::object cls, int64_t inputBatchDimension,
              int64_t inputFeatureDimension,
              const std::vector<int64_t> inputSpatialDimensions,
              int64_t kernelInputFeatureDimension,
@@ -349,15 +353,16 @@
                 outputSpatialDimensions.size(),
                 outputSpatialDimensions.data()));
           },
-          py::arg("cls"), py::arg("input_batch_dimension"),
-          py::arg("input_feature_dimension"),
-          py::arg("input_spatial_dimensions"),
-          py::arg("kernel_input_feature_dimension"),
-          py::arg("kernel_output_feature_dimension"),
-          py::arg("kernel_spatial_dimensions"),
-          py::arg("output_batch_dimension"),
-          py::arg("output_feature_dimension"),
-          py::arg("output_spatial_dimensions"), py::arg("ctx") = py::none(),
+          nb::arg("cls"), nb::arg("input_batch_dimension"),
+          nb::arg("input_feature_dimension"),
+          nb::arg("input_spatial_dimensions"),
+          nb::arg("kernel_input_feature_dimension"),
+          nb::arg("kernel_output_feature_dimension"),
+          nb::arg("kernel_spatial_dimensions"),
+          nb::arg("output_batch_dimension"),
+          nb::arg("output_feature_dimension"),
+          nb::arg("output_spatial_dimensions"),
+          nb::arg("ctx").none() = nb::none(),
           "Creates a ConvDimensionNumbers attribute with the given dimension "
           "configuration.")
       .def_property_readonly(
@@ -416,11 +421,11 @@
                 stablehloConvDimensionNumbersGetOutputSpatialDimensionsElem);
           });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "OutputOperandAlias", stablehloAttributeIsAOutputOperandAlias)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::vector<int64_t> outputTupleIndices,
+          [](nb::object cls, const std::vector<int64_t> outputTupleIndices,
              int64_t operandIndex,
              const std::vector<int64_t> operandTupleIndices, MlirContext ctx) {
             return cls(stablehloOutputOperandAliasGet(
@@ -428,9 +433,9 @@
                 operandIndex, operandTupleIndices.size(),
                 operandTupleIndices.data()));
           },
-          py::arg("cls"), py::arg("output_tuple_indices"),
-          py::arg("operand_index"), py::arg("operand_tuple_indices"),
-          py::arg("ctx") = py::none(),
+          nb::arg("cls"), nb::arg("output_tuple_indices"),
+          nb::arg("operand_index"), nb::arg("operand_tuple_indices"),
+          nb::arg("ctx").none() = nb::none(),
           "Creates a OutputOperandAlias attribute with the given tuple index.")
       .def_property_readonly(
           "output_tuple_indices",
@@ -450,114 +455,122 @@
             stablehloOutputOperandAliasGetOperandTupleIndicesElem);
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ComparisonDirectionAttr",
       stablehloAttributeIsAComparisonDirectionAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloComparisonDirectionAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a ComparisonDirection attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloComparisonDirectionAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ComparisonTypeAttr", stablehloAttributeIsAComparisonTypeAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloComparisonTypeAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a ComparisonType attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloComparisonTypeAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "PrecisionAttr", stablehloAttributeIsAPrecisionAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloPrecisionAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a Precision attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloPrecisionAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "FftTypeAttr", stablehloAttributeIsAFftTypeAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloFftTypeAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a FftType attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloFftTypeAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "TransposeAttr", stablehloAttributeIsATransposeAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloTransposeAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a Transpose attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloTransposeAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "RngDistributionAttr", stablehloAttributeIsARngDistributionAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloRngDistributionAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a RngDistribution attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloRngDistributionAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "RngAlgorithmAttr", stablehloAttributeIsARngAlgorithmAttr)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::string &value, MlirContext ctx) {
+          [](nb::object cls, const std::string &value, MlirContext ctx) {
             return cls(stablehloRngAlgorithmAttrGet(
                 ctx, mlirStringRefCreate(value.c_str(), value.size())));
           },
-          py::arg("cls"), py::arg("value"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("value"),
+          nb::arg("context").none() = nb::none(),
           "Creates a RngAlgorithm attribute with the given value.")
       .def_property_readonly("value", [](MlirAttribute self) {
         return toPyString(stablehloRngAlgorithmAttrGetValue(self));
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "ChannelHandle", stablehloAttributeIsChannelHandle)
       .def_classmethod(
           "get",
-          [](py::object cls, int64_t handle, int64_t type, MlirContext ctx) {
+          [](nb::object cls, int64_t handle, int64_t type, MlirContext ctx) {
             return cls(stablehloChannelHandleGet(ctx, handle, type));
           },
-          py::arg("cls"), py::arg("handle"), py::arg("type"),
-          py::arg("context") = py::none(), "Creates a ChannelHandle attribute.")
+          nb::arg("cls"), nb::arg("handle"), nb::arg("type"),
+          nb::arg("context").none() = nb::none(),
+          "Creates a ChannelHandle attribute.")
       .def_property_readonly("handle",
                              [](MlirAttribute self) {
                                return stablehloChannelHandleGetHandle(self);
@@ -568,16 +581,17 @@
         return stablehloChannelHandleGetType(self);
       });
 
-  mlir::python::adaptors::mlir_attribute_subclass(
+  mlir::python::nanobind_adaptors::mlir_attribute_subclass(
       m, "TypeExtensions", stablehloAttributeIsTypeExtensions)
       .def_classmethod(
           "get",
-          [](py::object cls, const std::vector<int64_t> &bounds,
+          [](nb::object cls, const std::vector<int64_t> &bounds,
              MlirContext ctx) {
             return cls(
                 stablehloTypeExtensionsGet(ctx, bounds.size(), bounds.data()));
           },
-          py::arg("cls"), py::arg("bounds"), py::arg("context") = py::none(),
+          nb::arg("cls"), nb::arg("bounds"),
+          nb::arg("context").none() = nb::none(),
           "Creates a TypeExtensions with the given bounds.")
       .def_property_readonly("bounds", [](MlirAttribute self) {
         return attributePropertyVector(self,
diff --ruN a/stablehlo/stablehlo/integrations/python/VhloModule.cpp b/stablehlo/stablehlo/integrations/python/VhloModule.cpp
--- stablehlo/stablehlo/integrations/python/VhloModule.cpp
+++ stablehlo/stablehlo/integrations/python/VhloModule.cpp
@@ -11,12 +11,13 @@
 ==============================================================================*/
 
 #include "mlir-c/IR.h"
-#include "mlir/Bindings/Python/PybindAdaptors.h"
+#include "mlir/Bindings/Python/NanobindAdaptors.h"
+#include "nanobind/nanobind.h"
 #include "stablehlo/integrations/c/VhloDialect.h"
 
-namespace py = pybind11;
+namespace nb = nanobind;
 
-PYBIND11_MODULE(_vhlo, m) {
+NB_MODULE(_vhlo, m) {
   m.doc() = "vhlo main python extension";
 
   //
@@ -32,5 +33,5 @@
           mlirDialectHandleLoadDialect(dialect, context);
         }
       },
-      py::arg("context"), py::arg("load") = true);
+      nb::arg("context"), nb::arg("load") = true);
 }
diff --ruN a/stablehlo/stablehlo/tests/ops_chlo.mlir b/stablehlo/stablehlo/tests/ops_chlo.mlir
--- stablehlo/stablehlo/tests/ops_chlo.mlir
+++ stablehlo/stablehlo/tests/ops_chlo.mlir
@@ -73,6 +73,222 @@
 
 // -----
 
+// ragged_dot mode 1: [b,m,k], [g,b,k,n], [g] -> [b,m,n]
+func.func @ragged_dot_non_contracting(%lhs : tensor<2x11x5xf32>, %rhs : tensor<3x2x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<2x11x7xf32> {
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [0],
+      rhs_batching_dimensions = [1],
+      lhs_contracting_dimensions = [2],
+      rhs_contracting_dimensions = [2],
+      lhs_ragged_dimensions = [1],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>
+  func.return %0 : tensor<2x11x7xf32>
+}
+
+// -----
+
+// ragged_dot mode 2: [m,k], [k,n], [g] -> [g,m,n]
+func.func @ragged_dot_contracting(%lhs : tensor<2x11x5xf32>, %rhs : tensor<2x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<3x2x11x7xf32> {
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [0],
+      rhs_batching_dimensions = [0],
+      lhs_contracting_dimensions = [2],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [2],
+      rhs_group_dimensions = []
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<2x11x5xf32>, tensor<2x5x7xf32>, tensor<3xi64>) -> tensor<3x2x11x7xf32>
+  func.return %0 : tensor<3x2x11x7xf32>
+}
+
+// -----
+
+// ragged_dot mode 3: [b,m,k], [b,k,n], [g] -> [b,m,n]
+func.func @ragged_dot_batch(%lhs : tensor<3x11x5xf32>, %rhs : tensor<3x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<3x11x7xf32> {
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [0],
+      rhs_batching_dimensions = [0],
+      lhs_contracting_dimensions = [2],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = []
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<3x11x5xf32>, tensor<3x5x7xf32>, tensor<3xi64>) -> tensor<3x11x7xf32>
+  func.return %0 : tensor<3x11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_incompatible_contracting_dims(%lhs : tensor<11x5xf32>, %rhs : tensor<3x2x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{contracting dimension sizes must match}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x5xf32>, tensor<3x2x7xf32>, tensor<3xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_group_sizes_incorrect_rank(%lhs : tensor<11x5xf32>, %rhs : tensor<3x5x7xf32>, %group_sizes : tensor<3x2xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{expected rank of group_sizes of ragged dot to be 1, got 2}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x5xf32>, tensor<3x5x7xf32>, tensor<3x2xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_group_sizes_incorrect_shape(%lhs : tensor<11x5xf32>, %rhs : tensor<3x5x7xf32>, %group_sizes : tensor<2xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{group_sizes is expected to have shape=[3], got [2]}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x5xf32>, tensor<3x5x7xf32>, tensor<2xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_incorrect_number_of_lhs_ragged_dimensions(%lhs : tensor<11x5xf32>, %rhs : tensor<3x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{There must be exactly one ragged dimension in the lhs}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [0, 1],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x5xf32>, tensor<3x5x7xf32>, tensor<3xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_rhs_group_dim_is_batch(%lhs : tensor<3x11x5xf32>, %rhs : tensor<3x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<3x11x7xf32> {
+  // @expected-error@+1 {{has duplicated dimension from rhs_group_dimensions and rhs_batching_dimensions: 0}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [0],
+      rhs_batching_dimensions = [0],
+      lhs_contracting_dimensions = [2],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [1],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<3x11x5xf32>, tensor<3x5x7xf32>, tensor<3xi64>) -> tensor<3x11x7xf32>
+  func.return %0 : tensor<3x11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_rhs_group_dim_is_contracting(%lhs : tensor<11x3xf32>, %rhs : tensor<3x3x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{has duplicated dimension from rhs_group_dimensions and rhs_contracting_dimensions: 1}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = [1]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x3xf32>, tensor<3x3x7xf32>, tensor<3xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_nonzero_rhs_group_dims_for_ragged_batch(%lhs : tensor<2x11x5xf32>, %rhs : tensor<3x2x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<2x11x7xf32> {
+  // @expected-error@+1 {{There must be zero group dimensions in the rhs when the ragged dimension is batch or contracting}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [0],
+      rhs_batching_dimensions = [1],
+      lhs_contracting_dimensions = [2],
+      rhs_contracting_dimensions = [2],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>
+  func.return %0 : tensor<2x11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_nonzero_rhs_group_dims_for_ragged_contracting(%lhs : tensor<11x5xf32>, %rhs : tensor<3x5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{There must be zero group dimensions in the rhs when the ragged dimension is batch or contracting}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [1],
+      lhs_ragged_dimensions = [1],
+      rhs_group_dimensions = [0]
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x5xf32>, tensor<3x5x7xf32>, tensor<3xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
+func.func @ragged_dot_zero_rhs_group_dims_for_ragged_noncontracting(%lhs : tensor<11x5xf32>, %rhs : tensor<5x7xf32>, %group_sizes : tensor<3xi64>) -> tensor<11x7xf32> {
+  // @expected-error@+1 {{There must be exactly one group dimension in the rhs when the lhs ragged dimension is non-contracting}}
+  %0 = "chlo.ragged_dot"(%lhs, %rhs, %group_sizes) {
+    ragged_dot_dimension_numbers = #chlo.ragged_dot<
+      lhs_batching_dimensions = [],
+      rhs_batching_dimensions = [],
+      lhs_contracting_dimensions = [1],
+      rhs_contracting_dimensions = [0],
+      lhs_ragged_dimensions = [0],
+      rhs_group_dimensions = []
+    >,
+    precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>]
+  } : (tensor<11x5xf32>, tensor<5x7xf32>, tensor<3xi64>) -> tensor<11x7xf32>
+  func.return %0 : tensor<11x7xf32>
+}
+
+// -----
+
 func.func @top_k(%arg0 : tensor<f32>) {
   // expected-error @+2 {{failed to infer returned types}}
   // @expected-error @+1{{operand's rank must be at least 1}}
diff --ruN a/stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp b/stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp
--- stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp
+++ stablehlo/stablehlo/transforms/StablehloRefineShapes.cpp
@@ -369,6 +369,10 @@
 // Which correlates to <func, sym_int_values, arg_types>
 class RefineShapeState {
  public:
+  RefineShapeState(
+      std::optional<AdditionalShapeRefinementPatternsFn> additionalPatternsFn)
+      : additionalPatternsFn(additionalPatternsFn) {}
+
   enum class RefinementState {
     NOT_ALREADY_REFINED,
     ALREADY_REFINED,
@@ -431,7 +435,14 @@
     });
   }
 
+  void addAdditionalPatterns(RewritePatternSet& patterns) {
+    if (additionalPatternsFn.has_value())
+      additionalPatternsFn.value()(&patterns);
+  }
+
  private:
+  std::optional<AdditionalShapeRefinementPatternsFn> additionalPatternsFn;
+
   // Maps refined functions to the refinement context: the values of dimension
   // arguments and the types of non-global-constant arguments. A function is
   // added here when we start refining it.
@@ -1001,7 +1012,7 @@
 LogicalResult applyShapeRefinementPatterns(func::FuncOp func,
                                            RefineShapeState& state) {
   MLIRContext* context = func.getContext();
-  RewritePatternSet patterns(context);
+  RewritePatternSet patterns(func->getContext());
   GreedyRewriteConfig config;
 
   // The algorithm behind this pass consists of a single traversal of the
@@ -1019,6 +1030,9 @@
   populateStablehloRefineShapesPatterns(&patterns, context);
   patterns.add<RefineCallOpPattern>(context, state);
 
+  // Populate additional patterns for StableHLO extensions.
+  state.addAdditionalPatterns(patterns);
+
   // The folding patterns implement partial evaluation of shape computations
   // which is a critical part of implementing type refinement for ops like
   // dynamic_broadcast_in_dim, dynamic_iota and dynamic_reshape whose shape
@@ -1103,14 +1117,22 @@
 
     // Start with empty state, and no dim args / token args.
     MLIRContext* context = func.getContext();
-    RefineShapeState state;
-    RefinementKey key(func, 0, {}, llvm::to_vector(func.getArgumentTypes()));
-    if (failed(refineFunction(*context, state, key)))
-      return signalPassFailure();
+    if (failed(refineEntryFunction(*context, func))) return signalPassFailure();
   }
 };
 
 }  // namespace
+
+LogicalResult refineEntryFunction(
+    MLIRContext& context, func::FuncOp func,
+    std::optional<AdditionalShapeRefinementPatternsFn> additionalPatternsFn) {
+  // Start with empty state, and no dim args / token args.
+  RefineShapeState state(additionalPatternsFn);
+  RefinementKey key(func, 0, {}, llvm::to_vector(func.getArgumentTypes()));
+  if (failed(refineFunction(context, state, key)))
+    return func.emitError("Failed to refine entry function");
+  return success();
+}
 
 func::FuncOp getStablehloRefineShapesTarget(ModuleOp module) {
   // Only one function per module is supported at the moment to avoid the need
diff --ruN a/stablehlo/stablehlo/transforms/StablehloRefineShapes.h b/stablehlo/stablehlo/transforms/StablehloRefineShapes.h
--- stablehlo/stablehlo/transforms/StablehloRefineShapes.h
+++ stablehlo/stablehlo/transforms/StablehloRefineShapes.h
@@ -101,6 +101,18 @@
   return refineReturnShape(rewriter, op, shape);
 }
 
+// Entrypoint for any pass adding extensibility to the StableHLO shape
+// refinement pass. If program is inlined before shape refinement,
+// populateShapeRefinementPatterns can be safely used, but if shape refinement
+// needs to operate on programs with functions and calls, then
+// additionalPatterns will need to be populated and passed in.
+using AdditionalShapeRefinementPatternsFn =
+    std::function<void(RewritePatternSet*)>;
+LogicalResult refineEntryFunction(
+    MLIRContext& context, func::FuncOp func,
+    std::optional<AdditionalShapeRefinementPatternsFn> additionalPatternsFn =
+        std::nullopt);
+
 // Custom call used to buffer operands for shape refinement
 // This is a temporary artifact that is introduced by StablehloRefineArguments
 // and is washed away during StablehloRefineShapes.

